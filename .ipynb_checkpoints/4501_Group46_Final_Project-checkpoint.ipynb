{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d063d72",
   "metadata": {},
   "source": [
    "# NYC Apartment Search by Group 46\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "\n",
    "Imagine that your apartment lease is nearing its end, and it's time to find  a new home in the heart of New York City! To guide us in this quest, we rely on a prudent budget, a preference for a serene neighborhood, and a desire for a touch of greenery. Leveraging the NYC Open Data, including 311 complaints, tree census, and Zillow's historic monthly rent averages, we embark on a data-driven exploration. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d4b0c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing the necessary libraries and modules. These include tools for data manipulation, visualization, and database interactions. Also, our project relies on a PostgreSQL database for storing and retrieving data. Below are the configuration details. We specify the locations for data files, such as shapefiles and CSVs, as well as constants like API tokens and base URLs for accessing external data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53894c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import subprocess\n",
    "import urllib.parse\n",
    "from math import ceil\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "from geopy.distance import geodesic\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon, mapping\n",
    "\n",
    "# SQLAlchemy imports for database interaction\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, MetaData, Table, text, func\n",
    "from sqlalchemy.ext.hybrid import hybrid_property\n",
    "from sqlalchemy.orm import Session, sessionmaker, declarative_base, column_property\n",
    "from geoalchemy2 import Geometry, WKTElement, functions as geo_func\n",
    "\n",
    "# GeoAlchemy2 extensions for geospatial data in SQLAlchemy\n",
    "from geoalchemy2.functions import ST_Point, ST_Distance\n",
    "\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "from geoalchemy2 import WKTElement\n",
    "\n",
    "\n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import psycopg2\n",
    "from shapely import wkb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71cf3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"egpaU4U1YY3mBGHMmdNqtmvpv\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"group46project\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_URL = f\"postgresql+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")\n",
    "\n",
    "##add new one\n",
    "# Create the data directory if it doesn't exist\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e163aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24c50e",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing\n",
    "\n",
    "In this stage, we take raw data and transform it into a clean and usable format. This process is important for making informed decisions about our future apartment because only with cleaned and organized data, can we analyze and visualize it. We are handling the following data:\n",
    "\n",
    "**Zipcode Data:** We leverage data on zipcodes, ensuring that each area is accurately represented. This includes removing unnecessary information and aligning the data to a standardized coordinate system.\n",
    "\n",
    "**311 Complaints Data:** We use the information provided by 311 complaints. By focusing on relevant details like the type of complaints and their locations, we gain insights into the quality of life in each area and make informed decisions about the desirability of potential neighborhoods for our new apartment.\n",
    "\n",
    "**Tree Data:** We explore the distribution of trees across neighborhoods, looking at factors like health and species diversity. By organizing information of these trees and their location (zipcodes, latitude, and longitude), we gain valuable insights into the green landscape of New York City.\n",
    "\n",
    "**Zillow's Rent Data:** We clean and organize this data to understand the rental prices over time, helping us make financially sound decisions. Through these steps, we ensure our data is accurate, complete, and ready for finding the apartment in the New York City.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef97869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    \"\"\"\n",
    "    Load and clean zipcode data from a shapefile.\n",
    "\n",
    "    This function reads a shapefile containing zipcode data, normalizes its coordinate\n",
    "    reference system to EPSG 4326 for consistency, retains only relevant columns,\n",
    "    and converts the zipcode to an integer format.\n",
    "\n",
    "    Parameters:\n",
    "    - `zipcode_datafile` (pathlib.Path): The file path to the shapefile containing zipcode data.\n",
    "\n",
    "    Returns:\n",
    "    - `gdf_cleaned` (geopandas.GeoDataFrame): A cleaned GeoDataFrame containing zipcode data.\n",
    "      The DataFrame includes columns 'zipcode' and 'geometry', with zipcode converted to integer.\n",
    "\n",
    "    Raises:\n",
    "    - `RuntimeError`: If an unexpected error occurs during the process.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Load the shapefile into a GeoDataFrame\n",
    "        gdf = gpd.read_file(zipcode_datafile)\n",
    "        \n",
    "        # Normalize to EPSG 4326 coordinate system for consistency across datasets\n",
    "        gdf_crs_normalized = gdf.to_crs(epsg=4326)\n",
    "        \n",
    "        # Select and rename relevant columns for further analysis\n",
    "        gdf_cleaned = gdf_crs_normalized[[\"ZIPCODE\", \"geometry\"]].copy()\n",
    "        gdf_cleaned.columns = [\"zipcode\", \"geometry\"]\n",
    "\n",
    "        # Convert zipcode to integer for uniform data type\n",
    "        gdf_cleaned['zipcode'] = gdf_cleaned['zipcode'].astype(int)\n",
    "    except Exception as e:\n",
    "        # General exception for unforeseen errors\n",
    "        raise RuntimeError(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    return gdf_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92113406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data(start_date='2015-01-01', end_date='2023-10-01', chunk_size=29999999):\n",
    "    \"\"\"\n",
    "    Download and clean 311 data from New York City for a specified date range.\n",
    "\n",
    "    This function downloads 311 service requests data from a specified start date to an end date, \n",
    "    cleans the data by dropping missing values and converting data types, and then transforms \n",
    "    it into a geopandas GeoDataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - `start_date` (str): The start date of the data range. Defaults to '2015-01-01'.\n",
    "    - `end_date` (str): The end date of the data range. Defaults to '2023-10-01'.\n",
    "    - `chunk_size` (int, optional): The size of each data chunk to be retrieved. Defaults to 29999999.\n",
    "\n",
    "    Returns:\n",
    "    - `geodf_311_data` (geopandas.GeoDataFrame): A GeoDataFrame containing cleaned 311 data, with columns including\n",
    "      'created_date', 'complaint_type', 'zipcode', and 'geometry'.\n",
    "      \n",
    "    Note:\n",
    "    The 311 data is obtained from the New York City open data API. The resulting GeoDataFrame is saved \n",
    "    as a CSV file named '311_DATA.csv' in the 'data' directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://data.cityofnewyork.us/resource/erm2-nwe9.json'\n",
    "    full_data = pd.DataFrame()\n",
    "\n",
    "    # Calculate the number of chunks needed based on the date range and chunk size\n",
    "    num_chunks = ceil((pd.to_datetime(end_date) - pd.to_datetime(start_date)).days / chunk_size)\n",
    "\n",
    "    for chunk in range(num_chunks):\n",
    "        offset = chunk * chunk_size\n",
    "        date_filter = f\"created_date between '{start_date}' and '{end_date}'\"\n",
    "        params = {\n",
    "            '$select': 'created_date, complaint_type, incident_zip, latitude, longitude',\n",
    "            '$where': date_filter,\n",
    "            '$limit': chunk_size,\n",
    "            '$offset': offset\n",
    "        }\n",
    "        headers = {'X-App-Token': NYC_DATA_APP_TOKEN}\n",
    "        \n",
    "        #request data\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "        data_chunk = pd.DataFrame(response.json())\n",
    "        # Clean the data: drop missing values and convert data types\n",
    "        data_chunk_cleaned = data_chunk.dropna(subset=['incident_zip', 'latitude', 'longitude'], how='any').copy()\n",
    "        data_chunk_cleaned['created_date'] = pd.to_datetime(data_chunk_cleaned['created_date'])\n",
    "        data_chunk_cleaned['zipcode'] = pd.to_numeric(data_chunk_cleaned['incident_zip'], errors='coerce').dropna().astype(int)\n",
    "        data_chunk_cleaned = data_chunk_cleaned.drop(columns=['incident_zip'])\n",
    "        full_data = pd.concat([full_data, data_chunk_cleaned], ignore_index=True)\n",
    "\n",
    "    # Ensure the directory for data saving exists\n",
    "    DATA_DIR = Path('data')\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    full_data.to_csv(DATA_DIR / '311_DATA.csv', index=False)\n",
    "    \n",
    "    # Convert to GeoDataFrame\n",
    "    geometry = gpd.points_from_xy(full_data['longitude'], full_data['latitude'])\n",
    "    geodf_311_data = gpd.GeoDataFrame(full_data, geometry=geometry, crs='EPSG:4326')\n",
    "    geodf_311_data = geodf_311_data.drop(columns=['longitude', 'latitude'])\n",
    "\n",
    "    return geodf_311_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9656db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    \"\"\"\n",
    "    Download and clean tree data from New York City open data.\n",
    "\n",
    "    This function downloads tree data from the New York City open data API, fills missing values \n",
    "    for certain columns, and transforms it into a GeoPandas GeoDataFrame, ready for further analysis.\n",
    "\n",
    "    Returns:\n",
    "    - `geodf_tree_data` (geopandas.GeoDataFrame): A GeoDataFrame containing cleaned tree data, \n",
    "      with columns including 'created_at', 'tree_id', 'health', 'status', 'spc_common', \n",
    "      'zipcode', 'latitude', 'longitude'.\n",
    "\n",
    "    Raises:\n",
    "    - `RuntimeError`: If an error occurs during the download process.\n",
    "\n",
    "    Note:\n",
    "    The resulting GeoDataFrame is saved as a CSV file named 'TREE_DATA.csv' in the 'data' directory.\n",
    " \n",
    "    \"\"\"   \n",
    "    \n",
    "    url = 'https://data.cityofnewyork.us/resource/5rq2-4hqu.json'\n",
    "    params = {\n",
    "        '$select': 'created_at, tree_id, health, status, spc_common, zipcode, latitude, longitude'\n",
    "    }\n",
    "    headers = {'X-App-Token': NYC_DATA_APP_TOKEN}\n",
    "\n",
    "    # Handle network and request errors\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()  # Will raise an HTTPError for unsuccessful status codes\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise RuntimeError(f\"Error downloading data: {e}\")\n",
    "\n",
    "    data = pd.DataFrame(response.json())\n",
    "    # Fill missing values for specific columns\n",
    "    columns_to_fillna = ['health', 'status', 'spc_common']\n",
    "    data[columns_to_fillna] = data[columns_to_fillna].fillna('None')\n",
    "\n",
    "    # Drop rows with missing zipcode, latitude, or longitude, and copy the dataframe\n",
    "    data_cleaned = data.dropna(subset=['zipcode', 'latitude', 'longitude'], how='any').copy()\n",
    "\n",
    "    # Convert 'created_at' to datetime and 'zipcode' to integer, handling errors\n",
    "    data_cleaned['created_at'] = pd.to_datetime(data_cleaned['created_at'])\n",
    "    data_cleaned['zipcode'] = pd.to_numeric(data_cleaned['zipcode'], errors='coerce').dropna().astype(int)\n",
    "\n",
    "    # Ensure the directory for data saving exists\n",
    "    DATA_DIR = Path('data')\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    data_cleaned.to_csv(DATA_DIR / 'TREE_DATA.csv', index=False)\n",
    "    \n",
    "    # Create GeoDataFrame with appropriate CRS\n",
    "    geometry = gpd.points_from_xy(data_cleaned['longitude'].astype(float), data_cleaned['latitude'].astype(float))\n",
    "    crs = 'EPSG:4326'\n",
    "    geodf_tree_data = gpd.GeoDataFrame(data_cleaned, geometry=geometry, crs=crs)\n",
    "    geodf_tree_data = geodf_tree_data.drop(columns=['longitude', 'latitude'])  # Remove original coordinate columns\n",
    "\n",
    "    return geodf_tree_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5867a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data():\n",
    "    \"\"\"\n",
    "    Load and clean Zillow rent data for New York City.\n",
    "\n",
    "    This function loads Zillow rent data, filters for New York City data, cleans and \n",
    "    transforms the data into a more usable format for analysis.\n",
    "\n",
    "    Returns:\n",
    "    - `zillow_ny` (pandas.DataFrame): Cleaned DataFrame with columns including 'zipcode', 'date', and 'rent'.\n",
    "\n",
    "    Raises:\n",
    "    - `FileNotFoundError`: If the file specified by `file_path` is not found.\n",
    "\n",
    "    Note:\n",
    "    The Zillow rent data is expected to be stored in a CSV file named 'zillow_rent_data.csv'\n",
    "    in the 'data' directory. The cleaned data is saved as 'cleaned_zillow_data.csv' in the same directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    file_path = DATA_DIR / 'zillow_rent_data.csv'\n",
    "\n",
    "    # Ensure the directory exists before reading the file\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        df_zillow = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    # Filter data for New York City\n",
    "    zillow_ny = df_zillow[df_zillow['City'] == 'New York'].copy()\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_delete = ['RegionID', 'SizeRank', 'RegionType', 'StateName', 'Metro']\n",
    "    zillow_ny.drop(columns=columns_to_delete, axis=1, inplace=True)\n",
    "\n",
    "    # Reset index and rename columns\n",
    "    zillow_ny.reset_index(drop=True, inplace=True)\n",
    "    zillow_ny.rename(columns={'RegionName': 'zipcode'}, inplace=True)\n",
    "\n",
    "    # Replace 0 with NaN and convert column names to lowercase\n",
    "    zillow_ny.replace(0, np.nan, inplace=True)\n",
    "    zillow_ny.columns = zillow_ny.columns.str.lower()\n",
    "\n",
    "    # Reshape the dataframe and convert 'date' to datetime format\n",
    "    zillow_ny = pd.melt(zillow_ny, id_vars=['zipcode', 'state', 'city', 'countyname'], \n",
    "                        var_name='date', value_name='rent')\n",
    "    zillow_ny['date'] = pd.to_datetime(zillow_ny['date'], errors='coerce', format='%Y-%m-%d')\n",
    "\n",
    "    # Round 'rent' to 2 decimal places and drop rows with NaN in 'rent'\n",
    "    zillow_ny['rent'] = zillow_ny['rent'].round(2)\n",
    "    zillow_ny.dropna(subset=['rent'], inplace=True)\n",
    "\n",
    "    # Save the cleaned data\n",
    "    zillow_ny.to_csv(DATA_DIR / 'cleaned_zillow_data.csv', index=False)\n",
    "\n",
    "    return zillow_ny.drop(columns=['state', 'city', 'countyname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d6d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    \"\"\"\n",
    "    Load all datasets that we cleaned.\n",
    "\n",
    "    Returns:\n",
    "    - `geodf_zipcode_data` (geopandas.GeoDataFrame): Cleaned GeoDataFrame containing zipcode data.\n",
    "    - `geodf_311_data` (geopandas.GeoDataFrame): Cleaned GeoDataFrame containing 311 data.\n",
    "    - `geodf_tree_data` (geopandas.GeoDataFrame): Cleaned GeoDataFrame containing tree data.\n",
    "    - `df_zillow_data` (pandas.DataFrame): Cleaned DataFrame containing Zillow rent data.\n",
    "    \"\"\"\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data()\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d786173",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e14cdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   zipcode   263 non-null    int32   \n",
      " 1   geometry  263 non-null    geometry\n",
      "dtypes: geometry(1), int32(1)\n",
      "memory usage: 3.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c0a5ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>POLYGON ((-73.80585 40.68291, -73.80569 40.682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>POLYGON ((-73.93740 40.67973, -73.93487 40.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>POLYGON ((-73.90294 40.67084, -73.90223 40.668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>POLYGON ((-73.95797 40.67066, -73.95576 40.670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>POLYGON ((-73.97208 40.65060, -73.97192 40.650...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode                                           geometry\n",
       "0    11436  POLYGON ((-73.80585 40.68291, -73.80569 40.682...\n",
       "1    11213  POLYGON ((-73.93740 40.67973, -73.93487 40.679...\n",
       "2    11212  POLYGON ((-73.90294 40.67084, -73.90223 40.668...\n",
       "3    11225  POLYGON ((-73.95797 40.67066, -73.95576 40.670...\n",
       "4    11218  POLYGON ((-73.97208 40.65060, -73.97192 40.650..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "708fa357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 23030861 entries, 0 to 23030860\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   created_date    datetime64[ns]\n",
      " 1   complaint_type  object        \n",
      " 2   zipcode         float64       \n",
      " 3   geometry        geometry      \n",
      "dtypes: datetime64[ns](1), float64(1), geometry(1), object(1)\n",
      "memory usage: 702.8+ MB\n"
     ]
    }
   ],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36bcc698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-30 23:59:58</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>POINT (-73.95918 40.65567)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-30 23:59:38</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>11361.0</td>\n",
       "      <td>POINT (-73.78752 40.76676)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-30 23:59:35</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>POINT (-73.98487 40.71950)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-30 23:59:34</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>11435.0</td>\n",
       "      <td>POINT (-73.79729 40.68750)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-30 23:59:28</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>POINT (-73.95795 40.65220)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_date           complaint_type  zipcode  \\\n",
       "0 2023-09-30 23:59:58  Noise - Street/Sidewalk  11226.0   \n",
       "1 2023-09-30 23:59:38      Noise - Residential  11361.0   \n",
       "2 2023-09-30 23:59:35       Noise - Commercial  10002.0   \n",
       "3 2023-09-30 23:59:34      Noise - Residential  11435.0   \n",
       "4 2023-09-30 23:59:28      Noise - Residential  11226.0   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (-73.95918 40.65567)  \n",
       "1  POINT (-73.78752 40.76676)  \n",
       "2  POINT (-73.98487 40.71950)  \n",
       "3  POINT (-73.79729 40.68750)  \n",
       "4  POINT (-73.95795 40.65220)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "831e511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   created_at  1000 non-null   datetime64[ns]\n",
      " 1   tree_id     1000 non-null   object        \n",
      " 2   health      1000 non-null   object        \n",
      " 3   status      1000 non-null   object        \n",
      " 4   spc_common  1000 non-null   object        \n",
      " 5   zipcode     1000 non-null   int32         \n",
      " 6   geometry    1000 non-null   geometry      \n",
      "dtypes: datetime64[ns](1), geometry(1), int32(1), object(4)\n",
      "memory usage: 50.9+ KB\n"
     ]
    }
   ],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "288dedd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tree_id</th>\n",
       "      <th>health</th>\n",
       "      <th>status</th>\n",
       "      <th>spc_common</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-27</td>\n",
       "      <td>180683</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Alive</td>\n",
       "      <td>red maple</td>\n",
       "      <td>11375</td>\n",
       "      <td>POINT (-73.84422 40.72309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-03</td>\n",
       "      <td>200540</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Alive</td>\n",
       "      <td>pin oak</td>\n",
       "      <td>11357</td>\n",
       "      <td>POINT (-73.81868 40.79411)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-05</td>\n",
       "      <td>204026</td>\n",
       "      <td>Good</td>\n",
       "      <td>Alive</td>\n",
       "      <td>honeylocust</td>\n",
       "      <td>11211</td>\n",
       "      <td>POINT (-73.93661 40.71758)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-05</td>\n",
       "      <td>204337</td>\n",
       "      <td>Good</td>\n",
       "      <td>Alive</td>\n",
       "      <td>honeylocust</td>\n",
       "      <td>11211</td>\n",
       "      <td>POINT (-73.93446 40.71354)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-30</td>\n",
       "      <td>189565</td>\n",
       "      <td>Good</td>\n",
       "      <td>Alive</td>\n",
       "      <td>American linden</td>\n",
       "      <td>11215</td>\n",
       "      <td>POINT (-73.97598 40.66678)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  created_at tree_id health status       spc_common  zipcode  \\\n",
       "0 2015-08-27  180683   Fair  Alive        red maple    11375   \n",
       "1 2015-09-03  200540   Fair  Alive          pin oak    11357   \n",
       "2 2015-09-05  204026   Good  Alive      honeylocust    11211   \n",
       "3 2015-09-05  204337   Good  Alive      honeylocust    11211   \n",
       "4 2015-08-30  189565   Good  Alive  American linden    11215   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (-73.84422 40.72309)  \n",
       "1  POINT (-73.81868 40.79411)  \n",
       "2  POINT (-73.93661 40.71758)  \n",
       "3  POINT (-73.93446 40.71354)  \n",
       "4  POINT (-73.97598 40.66678)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a66b49bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9039 entries, 5 to 15224\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   zipcode  9039 non-null   int64         \n",
      " 1   date     9039 non-null   datetime64[ns]\n",
      " 2   rent     9039 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 282.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8367cb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>date</th>\n",
       "      <th>rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11226</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>1944.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10025</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>3068.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11206</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2482.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11221</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2125.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11235</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>1687.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zipcode       date     rent\n",
       "5     11226 2015-01-31  1944.61\n",
       "7     10025 2015-01-31  3068.95\n",
       "13    11206 2015-01-31  2482.83\n",
       "14    11221 2015-01-31  2125.74\n",
       "20    11235 2015-01-31  1687.79"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004b6ff",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data\n",
    "\n",
    "In this phase, we transition from the four datasets that we cleaned from Part one to the PostgreSQL database, creating a foundation for seamless data querying and analysis. \n",
    "\n",
    "First, we need to create a database to store data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaafe662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_new_postgis_database(username, db_name):\n",
    "    \"\"\"\n",
    "    Set up a new PostgreSQL database with the PostGIS extension.\n",
    "\n",
    "    Args:\n",
    "    - username (str): The PostgreSQL username.\n",
    "    - db_name (str): The name for the new database.\n",
    "\n",
    "    \"\"\"\n",
    "    # Create a new database\n",
    "    subprocess.run(['createdb', db_name])\n",
    "\n",
    "    # Enable PostGIS extension\n",
    "    subprocess.run(['psql', '-U', username, '--dbname', db_name, '-c', 'CREATE EXTENSION postgis;'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_new_postgis_database(DB_USER, DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0856d1f",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "After creating the datebase, we can now create tables for the datasets we gained from Part one, which is pretty much like a virtual spreadsheet that organizes specific types of information.\n",
    "\n",
    "For example, we have a 'zipcodes' table to store details about different zip codes, a 'nyc311s' table to store details about those 311 complaints, a 'trees' table for information about trees, and a 'zillow_datas' table for rental data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faaef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a76ebea",
   "metadata": {},
   "source": [
    "#### Using SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eef910",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class ZipCode(Base):\n",
    "    \"\"\"\n",
    "    Represents the ZipCode data with geometry as POLYGON.\n",
    "    \"\"\"\n",
    "    __tablename__ = 'zipcodes'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    zipcode = Column(Integer, index=True)  # Added index for faster query performance\n",
    "    geometry = Column(Geometry('POLYGON'))\n",
    "    \n",
    "class NYC311(Base):\n",
    "    \"\"\"\n",
    "    Represents the NYC 311 service request data with geometry as POINT.\n",
    "    \"\"\"\n",
    "    __tablename__ = 'nyc311s'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    created_date = Column(DateTime)\n",
    "    complaint_type = Column(String)\n",
    "    zipcode = Column(Integer, index=True)\n",
    "    geometry = Column(Geometry(geometry_type='POINT', srid=4326))\n",
    "\n",
    "    \n",
    "class Tree(Base):\n",
    "    \"\"\"\n",
    "    Represents the Tree data with geometry as POINT.\n",
    "    \"\"\"\n",
    "    __tablename__ = \"trees\"\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    created_at = Column(DateTime)\n",
    "    tree_id = Column(String)\n",
    "    health = Column(String)\n",
    "    status = Column(String)\n",
    "    spc_common = Column(String)\n",
    "    zipcode = Column(Integer, index=True)\n",
    "    geometry = Column(Geometry(geometry_type='POINT', srid=4326))\n",
    "\n",
    "class ZillowData(Base):\n",
    "    \"\"\"\n",
    "    Represents the Zillow rent data.\n",
    "    \"\"\"\n",
    "    __tablename__ = 'zillow_datas'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    zipcode = Column(Integer, index=True)\n",
    "    date = Column(DateTime)\n",
    "    rent = Column(Float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema.sql file\n",
    "with open(DB_SCHEMA_FILE, 'w') as file:\n",
    "    for table in Base.metadata.tables.values():\n",
    "        file.write(f\"CREATE TABLE IF NOT EXISTS {table.name} (\\n\")\n",
    "        for column in table.columns:\n",
    "            file.write(f\"   {column.name} {column.type},\\n\")\n",
    "        file.write(\");\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b73be",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "After setting up our tables, now we can add data to these tables in our database! Basically, we go through every dataset, including zip code data, 311 complaints data, tree data, and Zillow data that we organized in Part One, and store every piece of information in the corresponding tables!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f121f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Using SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d16df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = db.orm.sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into the database\n",
    "zipcodes = []\n",
    "for index, row in geodf_zipcode_data.iterrows():\n",
    "    zipcode = ZipCode(\n",
    "        zipcode=row['zipcode'],\n",
    "        geometry=f'SRID=4326;{row[\"geometry\"].wkt}'  # Directly use the WKT from the geometry column\n",
    "    )\n",
    "    zipcodes.append(zipcode)\n",
    "\n",
    "try:\n",
    "    session.add_all(zipcodes)  # Add all zipcode objects at once for efficiency\n",
    "    session.commit()  # Commit the transaction\n",
    "except Exception as e:\n",
    "    session.rollback()  # Rollback in case of any error\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81721994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataFrame with an \"id\" column\n",
    "geodf_311_data_geometry = gpd.GeoDataFrame(\n",
    "    geodf_311_data,\n",
    "    geometry='geometry',\n",
    "    crs=\"EPSG:4326\"  # Set the coordinate reference system if not already set\n",
    ")\n",
    "\n",
    "# Add an \"id\" column to the GeoDataFrame\n",
    "geodf_311_data_geometry['id'] = range(1, len(geodf_311_data_geometry) + 1)\n",
    "\n",
    "# Convert the GeoDataFrame to the specified table using to_postgis\n",
    "geodf_311_data_geometry.to_postgis(\n",
    "    \"nyc311s\",  # Specify the table name\n",
    "    engine,\n",
    "    if_exists=\"replace\",  # Use 'replace' or 'fail' based on your requirements\n",
    "    index=False,  # Set to True if you want to include the index in the database\n",
    "    dtype={\"geometry\": Geometry(\"POINT\", srid=4326)},  # Specify the data type for the geometry column\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b823ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_records = []\n",
    "for index, row in geodf_tree_data.iterrows():\n",
    "    tree_record = Tree(\n",
    "        created_at=row['created_at'],  \n",
    "        tree_id=row['tree_id'],   \n",
    "        health=row['health'],  \n",
    "        status=row['status'],  \n",
    "        spc_common=row['spc_common'],  \n",
    "        zipcode=row['zipcode'],   \n",
    "        geometry=f'SRID=4326;{row[\"geometry\"].wkt}'  # Directly use the WKT from the geometry column\n",
    "    )\n",
    "    tree_records.append(tree_record)\n",
    "\n",
    "try:\n",
    "    session.add_all(tree_records)  # Add all Tree records at once for efficiency\n",
    "    session.commit()  # Commit the transaction\n",
    "except Exception as e:\n",
    "    session.rollback()  # Rollback in case of any error\n",
    "    raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
