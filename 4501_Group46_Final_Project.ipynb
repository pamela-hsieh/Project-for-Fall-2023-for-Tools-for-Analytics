{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d063d72",
   "metadata": {},
   "source": [
    "# NYC Apartment Search by Group 46\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1BYVyFBDcTywdUlanH0ysfOrNWPgl7UkqXA7NeewTzxA/edit#heading=h.bpxu7uvknnbk)_\n",
    "\n",
    "\n",
    "Imagine that your apartment lease is nearing its end, and it's time to find  a new home in the heart of New York City! To guide us in this quest, we rely on a prudent budget, a preference for a serene neighborhood, and a desire for a touch of greenery. Leveraging the NYC Open Data, including 311 complaints, tree census, and Zillow's historic monthly rent averages, we embark on a data-driven exploration. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d4b0c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing the necessary libraries and modules. These include tools for data manipulation, visualization, and database interactions. Also, our project relies on a PostgreSQL database for storing and retrieving data. Below are the configuration details. We specify the locations for data files, such as shapefiles and CSVs, as well as constants like API tokens and base URLs for accessing external data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53894c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project, for example:\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import subprocess\n",
    "import urllib.parse\n",
    "from math import ceil\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "from geopy.distance import geodesic\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon, mapping\n",
    "\n",
    "# SQLAlchemy imports for database interaction\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, MetaData, Table, text, func\n",
    "from sqlalchemy.ext.hybrid import hybrid_property\n",
    "from sqlalchemy.orm import Session, sessionmaker, declarative_base, column_property\n",
    "from geoalchemy2 import Geometry, WKTElement, functions as geo_func\n",
    "\n",
    "# GeoAlchemy2 extensions for geospatial data in SQLAlchemy\n",
    "from geoalchemy2.functions import ST_Point, ST_Distance\n",
    "\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "from geoalchemy2 import WKTElement\n",
    "\n",
    "\n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import psycopg2\n",
    "from shapely import wkb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71cf3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"egpaU4U1YY3mBGHMmdNqtmvpv\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"group46project\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_URL = f\"postgresql+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")\n",
    "\n",
    "##add new one\n",
    "# Create the data directory if it doesn't exist\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e163aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24c50e",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing\n",
    "\n",
    "In this stage, we take raw data and transform it into a clean and usable format. This process is important for making informed decisions about our future apartment because only with cleaned and organized data, can we analyze and visualize it. We are handling the following data:\n",
    "\n",
    "**Zipcode Data:** We leverage data on zipcodes, ensuring that each area is accurately represented. This includes removing unnecessary information and aligning the data to a standardized coordinate system.\n",
    "\n",
    "**311 Complaints Data:** We use the information provided by 311 complaints. By focusing on relevant details like the type of complaints and their locations, we gain insights into the quality of life in each area and make informed decisions about the desirability of potential neighborhoods for our new apartment.\n",
    "\n",
    "**Tree Data:** We explore the distribution of trees across neighborhoods, looking at factors like health and species diversity. By organizing information of these trees and their location (zipcodes, latitude, and longitude), we gain valuable insights into the green landscape of New York City.\n",
    "\n",
    "**Zillow's Rent Data:** We clean and organize this data to understand the rental prices over time, helping us make financially sound decisions. Through these steps, we ensure our data is accurate, complete, and ready for finding the apartment in the New York City.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef97869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    \"\"\"\n",
    "    Load and clean zipcode data from a shapefile.\n",
    "\n",
    "    This function reads a shapefile containing zipcode data, normalizes its coordinate\n",
    "    reference system to EPSG 4326 for consistency, retains only relevant columns,\n",
    "    and converts the zipcode to an integer format.\n",
    "\n",
    "    Parameters:\n",
    "    - `zipcode_datafile` (pathlib.Path): The file path to the shapefile containing zipcode data.\n",
    "\n",
    "    Returns:\n",
    "    - `gdf_cleaned` (geopandas.GeoDataFrame): A cleaned GeoDataFrame containing zipcode data.\n",
    "      The DataFrame includes columns 'zipcode' and 'geometry', with zipcode converted to integer.\n",
    "\n",
    "    Raises:\n",
    "    - `RuntimeError`: If an unexpected error occurs during the process.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Load the shapefile into a GeoDataFrame\n",
    "        gdf = gpd.read_file(zipcode_datafile)\n",
    "        \n",
    "        # Normalize to EPSG 4326 coordinate system for consistency across datasets\n",
    "        gdf_crs_normalized = gdf.to_crs(epsg=4326)\n",
    "        \n",
    "        # Select and rename relevant columns for further analysis\n",
    "        gdf_cleaned = gdf_crs_normalized[[\"ZIPCODE\", \"geometry\"]].copy()\n",
    "        gdf_cleaned.columns = [\"zipcode\", \"geometry\"]\n",
    "\n",
    "        # Convert zipcode to integer for uniform data type\n",
    "        gdf_cleaned['zipcode'] = gdf_cleaned['zipcode'].astype(int)\n",
    "    except Exception as e:\n",
    "        # General exception for unforeseen errors\n",
    "        raise RuntimeError(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    return gdf_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92113406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data(start_date='2015-01-01', end_date='2023-10-01', chunk_size=29999999):\n",
    "    \"\"\"\n",
    "    Download and clean 311 data from New York City for a specified date range.\n",
    "\n",
    "    This function downloads 311 service requests data from a specified start date to an end date, \n",
    "    cleans the data by dropping missing values and converting data types, and then transforms \n",
    "    it into a geopandas GeoDataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - `start_date` (str): The start date of the data range. Defaults to '2015-01-01'.\n",
    "    - `end_date` (str): The end date of the data range. Defaults to '2023-10-01'.\n",
    "    - `chunk_size` (int, optional): The size of each data chunk to be retrieved. Defaults to 29999999.\n",
    "\n",
    "    Returns:\n",
    "    - `geodf_311_data` (geopandas.GeoDataFrame): A GeoDataFrame containing cleaned 311 data, with columns including\n",
    "      'created_date', 'complaint_type', 'zipcode', and 'geometry'.\n",
    "      \n",
    "    Note:\n",
    "    The 311 data is obtained from the New York City open data API. The resulting GeoDataFrame is saved \n",
    "    as a CSV file named '311_DATA.csv' in the 'data' directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://data.cityofnewyork.us/resource/erm2-nwe9.json'\n",
    "    full_data = pd.DataFrame()\n",
    "\n",
    "    # Calculate the number of chunks needed based on the date range and chunk size\n",
    "    num_chunks = ceil((pd.to_datetime(end_date) - pd.to_datetime(start_date)).days / chunk_size)\n",
    "\n",
    "    for chunk in range(num_chunks):\n",
    "        offset = chunk * chunk_size\n",
    "        date_filter = f\"created_date between '{start_date}' and '{end_date}'\"\n",
    "        params = {\n",
    "            '$select': 'created_date, complaint_type, incident_zip, latitude, longitude',\n",
    "            '$where': date_filter,\n",
    "            '$limit': chunk_size,\n",
    "            '$offset': offset\n",
    "        }\n",
    "        headers = {'X-App-Token': NYC_DATA_APP_TOKEN}\n",
    "        \n",
    "        #request data\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "        data_chunk = pd.DataFrame(response.json())\n",
    "        # Clean the data: drop missing values and convert data types\n",
    "        data_chunk_cleaned = data_chunk.dropna(subset=['incident_zip', 'latitude', 'longitude'], how='any').copy()\n",
    "        data_chunk_cleaned['created_date'] = pd.to_datetime(data_chunk_cleaned['created_date'])\n",
    "        data_chunk_cleaned['zipcode'] = pd.to_numeric(data_chunk_cleaned['incident_zip'], errors='coerce').dropna().astype(int)\n",
    "        data_chunk_cleaned = data_chunk_cleaned.drop(columns=['incident_zip'])\n",
    "        full_data = pd.concat([full_data, data_chunk_cleaned], ignore_index=True)\n",
    "\n",
    "    # Ensure the directory for data saving exists\n",
    "    DATA_DIR = Path('data')\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    full_data.to_csv(DATA_DIR / '311_DATA.csv', index=False)\n",
    "    \n",
    "    # Convert to GeoDataFrame\n",
    "    geometry = gpd.points_from_xy(full_data['longitude'], full_data['latitude'])\n",
    "    geodf_311_data = gpd.GeoDataFrame(full_data, geometry=geometry, crs='EPSG:4326')\n",
    "    geodf_311_data = geodf_311_data.drop(columns=['longitude', 'latitude'])\n",
    "\n",
    "    return geodf_311_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9656db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    \"\"\"\n",
    "    Download and clean tree data from New York City open data.\n",
    "\n",
    "    This function downloads tree data from the New York City open data API, fills missing values \n",
    "    for certain columns, and transforms it into a GeoPandas GeoDataFrame, ready for further analysis.\n",
    "\n",
    "    Returns:\n",
    "    - `geodf_tree_data` (geopandas.GeoDataFrame): A GeoDataFrame containing cleaned tree data, \n",
    "      with columns including 'created_at', 'tree_id', 'health', 'status', 'spc_common', \n",
    "      'zipcode', 'latitude', 'longitude'.\n",
    "\n",
    "    Raises:\n",
    "    - `RuntimeError`: If an error occurs during the download process.\n",
    "\n",
    "    Note:\n",
    "    The resulting GeoDataFrame is saved as a CSV file named 'TREE_DATA.csv' in the 'data' directory.\n",
    " \n",
    "    \"\"\"   \n",
    "    \n",
    "    url = 'https://data.cityofnewyork.us/resource/5rq2-4hqu.json'\n",
    "    params = {\n",
    "        '$select': 'created_at, tree_id, health, status, spc_common, zipcode, latitude, longitude'\n",
    "    }\n",
    "    headers = {'X-App-Token': NYC_DATA_APP_TOKEN}\n",
    "\n",
    "    # Handle network and request errors\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()  # Will raise an HTTPError for unsuccessful status codes\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise RuntimeError(f\"Error downloading data: {e}\")\n",
    "\n",
    "    data = pd.DataFrame(response.json())\n",
    "    # Fill missing values for specific columns\n",
    "    columns_to_fillna = ['health', 'status', 'spc_common']\n",
    "    data[columns_to_fillna] = data[columns_to_fillna].fillna('None')\n",
    "\n",
    "    # Drop rows with missing zipcode, latitude, or longitude, and copy the dataframe\n",
    "    data_cleaned = data.dropna(subset=['zipcode', 'latitude', 'longitude'], how='any').copy()\n",
    "\n",
    "    # Convert 'created_at' to datetime and 'zipcode' to integer, handling errors\n",
    "    data_cleaned['created_at'] = pd.to_datetime(data_cleaned['created_at'])\n",
    "    data_cleaned['zipcode'] = pd.to_numeric(data_cleaned['zipcode'], errors='coerce').dropna().astype(int)\n",
    "\n",
    "    # Ensure the directory for data saving exists\n",
    "    DATA_DIR = Path('data')\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    data_cleaned.to_csv(DATA_DIR / 'TREE_DATA.csv', index=False)\n",
    "    \n",
    "    # Create GeoDataFrame with appropriate CRS\n",
    "    geometry = gpd.points_from_xy(data_cleaned['longitude'].astype(float), data_cleaned['latitude'].astype(float))\n",
    "    crs = 'EPSG:4326'\n",
    "    geodf_tree_data = gpd.GeoDataFrame(data_cleaned, geometry=geometry, crs=crs)\n",
    "    geodf_tree_data = geodf_tree_data.drop(columns=['longitude', 'latitude'])  # Remove original coordinate columns\n",
    "\n",
    "    return geodf_tree_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5867a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data():\n",
    "    \"\"\"\n",
    "    Load and clean Zillow rent data for New York City.\n",
    "\n",
    "    This function loads Zillow rent data, filters for New York City data, cleans and \n",
    "    transforms the data into a more usable format for analysis.\n",
    "\n",
    "    Returns:\n",
    "    - `zillow_ny` (pandas.DataFrame): Cleaned DataFrame with columns including 'zipcode', 'date', and 'rent'.\n",
    "\n",
    "    Raises:\n",
    "    - `FileNotFoundError`: If the file specified by `file_path` is not found.\n",
    "\n",
    "    Note:\n",
    "    The Zillow rent data is expected to be stored in a CSV file named 'zillow_rent_data.csv'\n",
    "    in the 'data' directory. The cleaned data is saved as 'cleaned_zillow_data.csv' in the same directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    file_path = DATA_DIR / 'zillow_rent_data.csv'\n",
    "\n",
    "    # Ensure the directory exists before reading the file\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        df_zillow = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    # Filter data for New York City\n",
    "    zillow_ny = df_zillow[df_zillow['City'] == 'New York'].copy()\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_delete = ['RegionID', 'SizeRank', 'RegionType', 'StateName', 'Metro']\n",
    "    zillow_ny.drop(columns=columns_to_delete, axis=1, inplace=True)\n",
    "\n",
    "    # Reset index and rename columns\n",
    "    zillow_ny.reset_index(drop=True, inplace=True)\n",
    "    zillow_ny.rename(columns={'RegionName': 'zipcode'}, inplace=True)\n",
    "\n",
    "    # Replace 0 with NaN and convert column names to lowercase\n",
    "    zillow_ny.replace(0, np.nan, inplace=True)\n",
    "    zillow_ny.columns = zillow_ny.columns.str.lower()\n",
    "\n",
    "    # Reshape the dataframe and convert 'date' to datetime format\n",
    "    zillow_ny = pd.melt(zillow_ny, id_vars=['zipcode', 'state', 'city', 'countyname'], \n",
    "                        var_name='date', value_name='rent')\n",
    "    zillow_ny['date'] = pd.to_datetime(zillow_ny['date'], errors='coerce', format='%Y-%m-%d')\n",
    "\n",
    "    # Round 'rent' to 2 decimal places and drop rows with NaN in 'rent'\n",
    "    zillow_ny['rent'] = zillow_ny['rent'].round(2)\n",
    "    zillow_ny.dropna(subset=['rent'], inplace=True)\n",
    "\n",
    "    # Save the cleaned data\n",
    "    zillow_ny.to_csv(DATA_DIR / 'cleaned_zillow_data.csv', index=False)\n",
    "\n",
    "    return zillow_ny.drop(columns=['state', 'city', 'countyname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d6d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    \"\"\"\n",
    "    Load all datasets that we cleaned.\n",
    "\n",
    "    Returns:\n",
    "    - `geodf_zipcode_data` (geopandas.GeoDataFrame): Cleaned GeoDataFrame containing zipcode data.\n",
    "    - `geodf_311_data` (geopandas.GeoDataFrame): Cleaned GeoDataFrame containing 311 data.\n",
    "    - `geodf_tree_data` (geopandas.GeoDataFrame): Cleaned GeoDataFrame containing tree data.\n",
    "    - `df_zillow_data` (pandas.DataFrame): Cleaned DataFrame containing Zillow rent data.\n",
    "    \"\"\"\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data()\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d786173",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e14cdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   zipcode   263 non-null    int32   \n",
      " 1   geometry  263 non-null    geometry\n",
      "dtypes: geometry(1), int32(1)\n",
      "memory usage: 3.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c0a5ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>POLYGON ((-73.80585 40.68291, -73.80569 40.682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>POLYGON ((-73.93740 40.67973, -73.93487 40.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>POLYGON ((-73.90294 40.67084, -73.90223 40.668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>POLYGON ((-73.95797 40.67066, -73.95576 40.670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>POLYGON ((-73.97208 40.65060, -73.97192 40.650...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode                                           geometry\n",
       "0    11436  POLYGON ((-73.80585 40.68291, -73.80569 40.682...\n",
       "1    11213  POLYGON ((-73.93740 40.67973, -73.93487 40.679...\n",
       "2    11212  POLYGON ((-73.90294 40.67084, -73.90223 40.668...\n",
       "3    11225  POLYGON ((-73.95797 40.67066, -73.95576 40.670...\n",
       "4    11218  POLYGON ((-73.97208 40.65060, -73.97192 40.650..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "708fa357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 23030863 entries, 0 to 23030862\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   created_date    datetime64[ns]\n",
      " 1   complaint_type  object        \n",
      " 2   zipcode         float64       \n",
      " 3   geometry        geometry      \n",
      "dtypes: datetime64[ns](1), float64(1), geometry(1), object(1)\n",
      "memory usage: 702.8+ MB\n"
     ]
    }
   ],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36bcc698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-30 23:59:58</td>\n",
       "      <td>Noise - Street/Sidewalk</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>POINT (-73.95918 40.65567)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-30 23:59:38</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>11361.0</td>\n",
       "      <td>POINT (-73.78752 40.76676)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-30 23:59:35</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>POINT (-73.98487 40.71950)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-30 23:59:34</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>11435.0</td>\n",
       "      <td>POINT (-73.79729 40.68750)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-30 23:59:28</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>POINT (-73.95795 40.65220)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         created_date           complaint_type  zipcode  \\\n",
       "0 2023-09-30 23:59:58  Noise - Street/Sidewalk  11226.0   \n",
       "1 2023-09-30 23:59:38      Noise - Residential  11361.0   \n",
       "2 2023-09-30 23:59:35       Noise - Commercial  10002.0   \n",
       "3 2023-09-30 23:59:34      Noise - Residential  11435.0   \n",
       "4 2023-09-30 23:59:28      Noise - Residential  11226.0   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (-73.95918 40.65567)  \n",
       "1  POINT (-73.78752 40.76676)  \n",
       "2  POINT (-73.98487 40.71950)  \n",
       "3  POINT (-73.79729 40.68750)  \n",
       "4  POINT (-73.95795 40.65220)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "831e511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   created_at  1000 non-null   datetime64[ns]\n",
      " 1   tree_id     1000 non-null   object        \n",
      " 2   health      1000 non-null   object        \n",
      " 3   status      1000 non-null   object        \n",
      " 4   spc_common  1000 non-null   object        \n",
      " 5   zipcode     1000 non-null   int32         \n",
      " 6   geometry    1000 non-null   geometry      \n",
      "dtypes: datetime64[ns](1), geometry(1), int32(1), object(4)\n",
      "memory usage: 50.9+ KB\n"
     ]
    }
   ],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "288dedd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tree_id</th>\n",
       "      <th>health</th>\n",
       "      <th>status</th>\n",
       "      <th>spc_common</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-27</td>\n",
       "      <td>180683</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Alive</td>\n",
       "      <td>red maple</td>\n",
       "      <td>11375</td>\n",
       "      <td>POINT (-73.84422 40.72309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-03</td>\n",
       "      <td>200540</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Alive</td>\n",
       "      <td>pin oak</td>\n",
       "      <td>11357</td>\n",
       "      <td>POINT (-73.81868 40.79411)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-09-05</td>\n",
       "      <td>204026</td>\n",
       "      <td>Good</td>\n",
       "      <td>Alive</td>\n",
       "      <td>honeylocust</td>\n",
       "      <td>11211</td>\n",
       "      <td>POINT (-73.93661 40.71758)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-09-05</td>\n",
       "      <td>204337</td>\n",
       "      <td>Good</td>\n",
       "      <td>Alive</td>\n",
       "      <td>honeylocust</td>\n",
       "      <td>11211</td>\n",
       "      <td>POINT (-73.93446 40.71354)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-30</td>\n",
       "      <td>189565</td>\n",
       "      <td>Good</td>\n",
       "      <td>Alive</td>\n",
       "      <td>American linden</td>\n",
       "      <td>11215</td>\n",
       "      <td>POINT (-73.97598 40.66678)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  created_at tree_id health status       spc_common  zipcode  \\\n",
       "0 2015-08-27  180683   Fair  Alive        red maple    11375   \n",
       "1 2015-09-03  200540   Fair  Alive          pin oak    11357   \n",
       "2 2015-09-05  204026   Good  Alive      honeylocust    11211   \n",
       "3 2015-09-05  204337   Good  Alive      honeylocust    11211   \n",
       "4 2015-08-30  189565   Good  Alive  American linden    11215   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (-73.84422 40.72309)  \n",
       "1  POINT (-73.81868 40.79411)  \n",
       "2  POINT (-73.93661 40.71758)  \n",
       "3  POINT (-73.93446 40.71354)  \n",
       "4  POINT (-73.97598 40.66678)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a66b49bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9039 entries, 5 to 15224\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   zipcode  9039 non-null   int64         \n",
      " 1   date     9039 non-null   datetime64[ns]\n",
      " 2   rent     9039 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 282.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8367cb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>date</th>\n",
       "      <th>rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11226</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>1944.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10025</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>3068.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11206</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2482.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11221</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2125.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11235</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>1687.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    zipcode       date     rent\n",
       "5     11226 2015-01-31  1944.61\n",
       "7     10025 2015-01-31  3068.95\n",
       "13    11206 2015-01-31  2482.83\n",
       "14    11221 2015-01-31  2125.74\n",
       "20    11235 2015-01-31  1687.79"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f004b6ff",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data\n",
    "\n",
    "In this phase, we transition from the four datasets that we cleaned from Part one to the PostgreSQL database, creating a foundation for seamless data querying and analysis. \n",
    "\n",
    "First, we need to create a database to store data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaafe662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_new_postgis_database(username, db_name):\n",
    "    \"\"\"\n",
    "    Set up a new PostgreSQL database with the PostGIS extension.\n",
    "\n",
    "    Args:\n",
    "    - username (str): The PostgreSQL username.\n",
    "    - db_name (str): The name for the new database.\n",
    "\n",
    "    \"\"\"\n",
    "    # Create a new database\n",
    "    subprocess.run(['createdb', db_name])\n",
    "\n",
    "    # Enable PostGIS extension\n",
    "    subprocess.run(['psql', '-U', username, '--dbname', db_name, '-c', 'CREATE EXTENSION postgis;'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eec5c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_new_postgis_database(DB_USER, DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0856d1f",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n",
    "After creating the datebase, we can now create tables for the datasets we gained from Part one, which is pretty much like a virtual spreadsheet that organizes specific types of information.\n",
    "\n",
    "For example, we have a 'zipcodes' table to store details about different zip codes, a 'nyc311s' table to store details about those 311 complaints, a 'trees' table for information about trees, and a 'zillow_datas' table for rental data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5faaef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a76ebea",
   "metadata": {},
   "source": [
    "#### Using SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99eef910",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class ZipCode(Base):\n",
    "    \"\"\"\n",
    "    Represents the ZipCode data with geometry as POLYGON.\n",
    "    \"\"\"\n",
    "    __tablename__ = 'zipcodes'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    zipcode = Column(Integer, index=True)  # Added index for faster query performance\n",
    "    geometry = Column(Geometry('POLYGON'))\n",
    "    \n",
    "class NYC311(Base):\n",
    "    \"\"\"\n",
    "    Represents the NYC 311 service request data with geometry as POINT.\n",
    "    \"\"\"\n",
    "    __tablename__ = 'nyc311s'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    created_date = Column(DateTime)\n",
    "    complaint_type = Column(String)\n",
    "    zipcode = Column(Integer, index=True)\n",
    "    geometry = Column(Geometry(geometry_type='POINT', srid=4326))\n",
    "\n",
    "    \n",
    "class Tree(Base):\n",
    "    \"\"\"\n",
    "    Represents the Tree data with geometry as POINT.\n",
    "    \"\"\"\n",
    "    __tablename__ = \"trees\"\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    created_at = Column(DateTime)\n",
    "    tree_id = Column(String)\n",
    "    health = Column(String)\n",
    "    status = Column(String)\n",
    "    spc_common = Column(String)\n",
    "    zipcode = Column(Integer, index=True)\n",
    "    geometry = Column(Geometry(geometry_type='POINT', srid=4326))\n",
    "\n",
    "class ZillowData(Base):\n",
    "    \"\"\"\n",
    "    Represents the Zillow rent data.\n",
    "    \"\"\"\n",
    "    __tablename__ = 'zillow_datas'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    zipcode = Column(Integer, index=True)\n",
    "    date = Column(DateTime)\n",
    "    rent = Column(Float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a47c7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema.sql file\n",
    "with open(DB_SCHEMA_FILE, 'w') as file:\n",
    "    for table in Base.metadata.tables.values():\n",
    "        file.write(f\"CREATE TABLE IF NOT EXISTS {table.name} (\\n\")\n",
    "        for column in table.columns:\n",
    "            file.write(f\"   {column.name} {column.type},\\n\")\n",
    "        file.write(\");\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f49e4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b73be",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "After setting up our tables, now we can add data to these tables in our database! Basically, we go through every dataset, including zip code data, 311 complaints data, tree data, and Zillow data that we organized in Part One, and store every piece of information in the corresponding tables!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d278966",
   "metadata": {},
   "source": [
    "#### Using SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1d16df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = db.orm.sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a486f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into the database\n",
    "zipcodes = []\n",
    "for index, row in geodf_zipcode_data.iterrows():\n",
    "    zipcode = ZipCode(\n",
    "        zipcode=row['zipcode'],\n",
    "        geometry=f'SRID=4326;{row[\"geometry\"].wkt}'  # Directly use the WKT from the geometry column\n",
    "    )\n",
    "    zipcodes.append(zipcode)\n",
    "\n",
    "try:\n",
    "    session.add_all(zipcodes)  # Add all zipcode objects at once for efficiency\n",
    "    session.commit()  # Commit the transaction\n",
    "except Exception as e:\n",
    "    session.rollback()  # Rollback in case of any error\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81721994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataFrame with an \"id\" column\n",
    "geodf_311_data_geometry = gpd.GeoDataFrame(\n",
    "    geodf_311_data,\n",
    "    geometry='geometry',\n",
    "    crs=\"EPSG:4326\"  # Set the coordinate reference system if not already set\n",
    ")\n",
    "\n",
    "# Add an \"id\" column to the GeoDataFrame\n",
    "geodf_311_data_geometry['id'] = range(1, len(geodf_311_data_geometry) + 1)\n",
    "\n",
    "# Convert the GeoDataFrame to the specified table using to_postgis\n",
    "geodf_311_data_geometry.to_postgis(\n",
    "    \"nyc311s\",  # Specify the table name\n",
    "    engine,\n",
    "    if_exists=\"replace\",  # Use 'replace' or 'fail' based on your requirements\n",
    "    index=False,  # Set to True if you want to include the index in the database\n",
    "    dtype={\"geometry\": Geometry(\"POINT\", srid=4326)},  # Specify the data type for the geometry column\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b823ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_records = []\n",
    "for index, row in geodf_tree_data.iterrows():\n",
    "    tree_record = Tree(\n",
    "        created_at=row['created_at'],  \n",
    "        tree_id=row['tree_id'],   \n",
    "        health=row['health'],  \n",
    "        status=row['status'],  \n",
    "        spc_common=row['spc_common'],  \n",
    "        zipcode=row['zipcode'],   \n",
    "        geometry=f'SRID=4326;{row[\"geometry\"].wkt}'  # Directly use the WKT from the geometry column\n",
    "    )\n",
    "    tree_records.append(tree_record)\n",
    "\n",
    "try:\n",
    "    session.add_all(tree_records)  # Add all Tree records at once for efficiency\n",
    "    session.commit()  # Commit the transaction\n",
    "except Exception as e:\n",
    "    session.rollback()  # Rollback in case of any error\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd469545",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_data_records = []\n",
    "for index, row in df_zillow_data.iterrows():\n",
    "    zillow_data_record = ZillowData(\n",
    "        zipcode=row['zipcode'],\n",
    "        date=row['date'],\n",
    "        rent=row['rent']\n",
    "    )\n",
    "    zillow_data_records.append(zillow_data_record)\n",
    "\n",
    "try:\n",
    "    session.add_all(zillow_data_records)  # Add all Zillow data records at once for efficiency\n",
    "    session.commit()  # Commit the transaction\n",
    "except Exception as e:\n",
    "    session.rollback()  # Rollback in case of any error\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4de9448",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data\n",
    "\n",
    "After we set up all data, tables, and the database, we can use queries to extract meaningful answers to various aspects of apartments, dividing the analysis into six distinct parts to unravel specific parts of the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c56b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    \"\"\"\n",
    "    Write a SQL query to a file.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The SQL query to be written to the file.\n",
    "    - outfile (str): The file path where the SQL query will be saved.\n",
    "    \"\"\"\n",
    "        \n",
    "    with open(outfile, 'w') as file:\n",
    "        file.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fcaaa7",
   "metadata": {},
   "source": [
    "### Query 1 - The Calm Places\n",
    "\n",
    "We're seeking data on the ten zip codes with the fewest 311 complaints between October 1st, 2022, and September 30th, 2023. The result is presented in two columns, displaying each zip code and its corresponding count of complaints in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9db6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = QUERY_DIR / \"top_10_zipcodes_by_calmness.sql\"\n",
    "\n",
    "\n",
    "# SQL query for Query 1: Count of complaints by zipcode within a specified date range\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT zipcode, COUNT(id)\n",
    "FROM  nyc311s\n",
    "WHERE created_date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "GROUP BY zipcode\n",
    "ORDER BY COUNT(id) DESC\n",
    "\"\"\"\n",
    "\n",
    "# Establish a database connection and execute the SQL query\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_1))\n",
    "    \n",
    "    # Iterate through the query result and print zipcode and complaint counts\n",
    "    for row in result:\n",
    "        print(f\"zipcode :{row[0]}, Complain Counts: {row[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c86cb4",
   "metadata": {},
   "source": [
    "### Query 2 - The Greenery Spots\n",
    "\n",
    "We would like explore the ten zip codes where the tree density is the highest only through the trees table. result should have two columns, 10 rows. The output consists of two columns, with each row representing a zip code and its corresponding total number of trees. The results should be sorted in descending order based on the total number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = QUERY_DIR / \"top_10_zipcodes_by_trees.sql\"\n",
    "\n",
    "\n",
    "# SQL query for Query 2: Top 10 zip codes with the highest count of trees\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT zipcode, COUNT(id)\n",
    "FROM  trees\n",
    "GROUP BY zipcode\n",
    "ORDER BY COUNT(id) DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1b95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection and execute the SQL query\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_2))\n",
    "    \n",
    "    # Iterate through the query result and print zipcode and tree counts\n",
    "    for row in result:\n",
    "        print(f\"Zipcode: {row[0]}, Tree Counts: {row[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a45581",
   "metadata": {},
   "source": [
    "### Query 3 - Evaluating Rent Feasibility Amidst Greenery\n",
    "\n",
    "In August 2023, we would like to know the 10 zip codes with the highest tree density and understanding the associated rental costs to assess affordability. The output features two columns and 10 rows, sorted in descending order based on total tree count, with rent information included in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f62485",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = QUERY_DIR / \"rents_for_top10_greenery_zipcodes.sql\"\n",
    "\n",
    "\n",
    "# SQL query for Query 3: Average rent for the top 10 tree-rich zip codes in August 2023\n",
    "QUERY_3 = \"\"\"\n",
    "SELECT zillow_datas.zipcode, TO_CHAR(AVG(zillow_datas.rent), 'FM9,999,999.00') AS average_rent\n",
    "FROM zillow_datas\n",
    "JOIN (\n",
    "    SELECT trees.zipcode, COUNT(trees.id) AS tree_count\n",
    "    FROM trees\n",
    "    GROUP BY trees.zipcode\n",
    "    ORDER BY COUNT(trees.id) DESC\n",
    "    LIMIT 10\n",
    ") AS top_trees_zipcodes ON zillow_datas.zipcode = top_trees_zipcodes.zipcode\n",
    "WHERE zillow_datas.date >= '2023-08-01' AND zillow_datas.date < '2023-09-01'\n",
    "GROUP BY zillow_datas.zipcode, top_trees_zipcodes.tree_count\n",
    "ORDER BY top_trees_zipcodes.tree_count DESC\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868af912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection and execute the SQL query\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_3))\n",
    "    \n",
    "    # Iterate through the query result and print zipcode and average rent\n",
    "    for row in result:\n",
    "        print(f\"Zipcode: {row[0]}, Average Rent: ${row[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac94d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960db461",
   "metadata": {},
   "source": [
    "### Query 4 - Correlation between Rent, Trees, and Complaints\n",
    "\n",
    "In January 2023, we are interested in data on the 5 zip codes with the lowest and highest average rent, along with tree and complaint counts, to explore potential correlations. The result is presented in 4 columns (zip code, average rent, tree count, and complaint count) and consist of 10 rows. This includes five rows with the highest average rent and five rows with the lowest average rent, with the rent figures included in the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = QUERY_DIR / \"rents_trees_complaints_analysis.sql\"\n",
    "\n",
    "\n",
    "# SQL query for Query 4: Analysis of rent, complaints, and tree counts for top 5 and bottom 5 zip codes by rent in January 2023\n",
    "QUERY_4 = \"\"\"\n",
    "WITH Rentranking AS (\n",
    "    SELECT\n",
    "        zipcode,\n",
    "        AVG(rent) AS average_rent,\n",
    "        ROW_NUMBER() OVER (ORDER BY AVG(rent) ASC) AS low_rank,\n",
    "        ROW_NUMBER() OVER (ORDER BY AVG(rent) DESC) AS high_rank\n",
    "    FROM\n",
    "        zillow_datas\n",
    "    WHERE\n",
    "        date = '2023-01-31'\n",
    "    GROUP BY zipcode\n",
    "),\n",
    "top5rent AS (\n",
    "    SELECT zipcode, average_rent\n",
    "    FROM Rentranking\n",
    "    WHERE low_rank <= 5 OR high_rank <= 5\n",
    "),\n",
    "complaint AS (\n",
    "    SELECT zipcode, COUNT(*) as complaint_count\n",
    "    FROM nyc311s\n",
    "    WHERE created_date >= TIMESTAMP '2023-01-01 00:00:00'\n",
    "    AND created_date < TIMESTAMP '2023-01-31 23:59:59'\n",
    "    GROUP BY zipcode\n",
    "),\n",
    "tree AS (\n",
    "    SELECT zipcode, COUNT(*) as tree_count\n",
    "    FROM trees\n",
    "    GROUP BY zipcode\n",
    ")\n",
    "SELECT \n",
    "    top5rent.zipcode, \n",
    "    TO_CHAR(top5rent.average_rent, 'FM9,999,999.00') AS rent, \n",
    "    COALESCE(complaint.complaint_count, 0) as complaint_count, \n",
    "    COALESCE(tree.tree_count, 0) as tree_count\n",
    "FROM \n",
    "    top5rent\n",
    "LEFT JOIN \n",
    "    complaint ON top5rent.zipcode = complaint.zipcode\n",
    "LEFT JOIN \n",
    "    tree ON top5rent.zipcode = tree.zipcode\n",
    "ORDER BY top5rent.average_rent DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection and execute the SQL query\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_4))\n",
    "    \n",
    "    # Iterate through the query result and print zipcode, rent, complaint count, and tree count\n",
    "    for row in result:\n",
    "        print(f\"Zipcode: {row[0]}, Rent: ${row[1]}, Complaint Count: {row[2]}, Tree Count: {row[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c6f788",
   "metadata": {},
   "source": [
    "### Query 5 - Another Approach to the Greenery Corners\n",
    "\n",
    "Recalling the top 10 zipcodes with the most trees from Query 2, we're now merging the trees and zipcode tables to locate trees within each zipcode's area, aiming for the same results, which is presented in two columns and consist of 10 rows. The rows should be sorted in descending order based on the total number of trees in each zip code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a47470",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = QUERY_DIR / \"tree_by_zipcode_with_polygon.sql\"\n",
    "\n",
    "\n",
    "# SQL query for Query 5: Top 10 zip codes with the highest tree counts based on spatial join\n",
    "QUERY_5 = \"\"\"\n",
    "WITH TreeCounts AS (\n",
    "    SELECT zipcodes.zipcode, trees.id\n",
    "    FROM zipcodes\n",
    "    LEFT JOIN trees ON ST_Within(trees.geometry, zipcodes.geometry)\n",
    ")\n",
    "\n",
    "SELECT zipcode, COUNT(DISTINCT id) AS tree_count\n",
    "FROM TreeCounts\n",
    "GROUP BY zipcode\n",
    "ORDER BY tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a database connection and execute the SQL query\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_5))\n",
    "    \n",
    "    # Iterate through the query result and print zipcode and tree count\n",
    "    for row in result:\n",
    "        print(f\"Zipcode: {row[0]}, Tree Count: {row[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc617f79",
   "metadata": {},
   "source": [
    "### Query 6 - Nearby Trees within a 0.5 Mile Radius.\"\n",
    "\n",
    "We aim to gather information about trees, such as species, health, and status, within a 0.5-mile radius of a specified location. The output is consist of 5 columns (ID, species, health, status, and coordinate location) for each tree in the specified radius.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ebdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6_FILENAME = QUERY_DIR / \"tree_info_in_certain_half_mile_radius.sql\"\n",
    "\n",
    "\n",
    "pointfive=0.5*1609.34\n",
    "\n",
    "QUERY_6 = '''\n",
    "SELECT trees.id, trees.spc_common, trees.health, trees.status, ST_AsText(trees.geometry)\n",
    "FROM trees\n",
    "WHERE ST_Distance(trees.geometry, ST_SetSRID(ST_MakePoint(-73.96253174434912, 40.80737875669467), 4326)) <= :pointfive\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(QUERY_6).bindparams(pointfive=pointfive))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d204cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03924410",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "Finally, in Part 4, we are creating 6 visual plots and charts to to illuminate various facets of life in New York City. These visualizations offer a comprehensive view, encompassing details on NYC rents, greenery, noise levels, and geographical locations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74209237",
   "metadata": {},
   "source": [
    "### Visualization 1 - Daily Trends for Top 3 NYC Complaints (Oct '22 - Sep '23).\n",
    "\n",
    "Firstly, we focus on the daily occurrences for the top 3 complaint types from October 2022 to September 2023, offering a detailed look at their frequency trends throughout this timeframe. This line chart displays the daily complaint trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46824fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure using the 'notebook' backend for Jupyter which supports interactive plots\n",
    "%matplotlib notebook\n",
    "\n",
    "def plot_daily_complaint_trends(df):\n",
    "    \"\"\"\n",
    "    Create an animated line plot of complaints over time for different complaint types.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Input DataFrame containing information about complaints over time.\n",
    "    \n",
    "    Returns:\n",
    "    - HTML: Displays the animated plot in the notebook.\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    # Assuming df is your DataFrame and it's already sorted by 'created_date'\n",
    "    df['created_date'] = pd.to_datetime(df['created_date'])\n",
    "    df.sort_values('created_date', inplace=True)\n",
    "    \n",
    "    # Initialize the figure and line objects for animation\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    lines = [ax.plot([], [], label=complaint_type)[0] for complaint_type in df['complaint_type'].unique()]\n",
    "\n",
    "    # Set the title and labels\n",
    "    ax.set_title('Complaints over Time')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "    # Function to initialize the background of the animation\n",
    "    def init():\n",
    "        for line in lines:\n",
    "            line.set_data([], [])\n",
    "        return lines\n",
    "\n",
    "    # Function to update the data of each line at each frame\n",
    "    def animate(i):\n",
    "        for line, complaint_type in zip(lines, df['complaint_type'].unique()):\n",
    "            # Filter the DataFrame for the current complaint type and get data up to the current frame\n",
    "            temp_df = df[df['complaint_type'] == complaint_type].iloc[:i+1]\n",
    "            line.set_data(temp_df['created_date'], temp_df['count'])\n",
    "        return lines\n",
    "\n",
    "    # Set plot limits\n",
    "    ax.set_xlim(df['created_date'].min(), df['created_date'].max())\n",
    "    ax.set_ylim(df['count'].min(), df['count'].max())\n",
    "    \n",
    "    # Include a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Create the animation object\n",
    "    anim = FuncAnimation(fig, animate, init_func=init, frames=len(df), interval=200, blit=True)\n",
    "\n",
    "    # Convert the animation to HTML using to_jshtml and display it\n",
    "    return HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f17da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1(engine):\n",
    "    # Find the top 3 complaint types for October 1st, 2022, to September 30th, 2023\n",
    "    top_complaint_types_query = \"\"\"\n",
    "    SELECT complaint_type, COUNT(id) AS count\n",
    "    FROM nyc311s\n",
    "    WHERE created_date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "    GROUP BY complaint_type\n",
    "    ORDER BY COUNT(id) DESC\n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    "    top_complaint_types = pd.read_sql_query(top_complaint_types_query, engine)\n",
    "\n",
    "\n",
    "    # Get daily counts for the top 3 complaint types\n",
    "    top_complaints = tuple(top_complaint_types['complaint_type'])\n",
    "    daily_counts_query = \"\"\"\n",
    "    SELECT DATE(created_date) as created_date, complaint_type, COUNT(id) AS count\n",
    "    FROM nyc311s\n",
    "    WHERE created_date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "    AND complaint_type IN %(complaint_types)s\n",
    "    GROUP BY DATE(created_date), complaint_type\n",
    "    ORDER BY created_date, complaint_type\n",
    "    \"\"\"\n",
    "    daily_counts = pd.read_sql_query(daily_counts_query, engine, params={'complaint_types': top_complaints})\n",
    "\n",
    "    return daily_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1(engine)\n",
    "plot_daily_complaint_trends(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512bcca5",
   "metadata": {},
   "source": [
    "### Visualization 2 - Top 10 Complaints by Type in Zip Code 10027 (Oct '18 - Sep '23).\n",
    "\n",
    "We are exploring the Top 10 Complaint Types in Zip Code 10027. This bar chart shows the frequency of each complaint type, providing insights into the predominant concerns within this area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe77910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_complaints_numbers(dataframe):\n",
    "    \"\"\"\n",
    "    Plot a bar chart showing the number of complaints by type in a specified zip code.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe (DataFrame): Input DataFrame containing information about complaints.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays a bar chart in the notebook.\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    figure, axes = plt.subplots(figsize=(15, 8))\n",
    "    complaint_types = dataframe['complaint_type']\n",
    "    values = dataframe['count']\n",
    "    axes.bar(complaint_types, values, color='orange')\n",
    "    axes.set_title(f\"Number of Complaints by Type in Zip Code 10027\")\n",
    "    axes.set_xlabel(\"Complaint Type\")\n",
    "    axes.set_ylabel(\"Number of Complaints\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_2():\n",
    "    query = \"\"\"\n",
    "    SELECT complaint_type, COUNT(id) AS count\n",
    "    FROM  nyc311s\n",
    "    WHERE created_date BETWEEN '2018-10-01' AND '2023-09-30'\n",
    "          AND zipcode = '10027'\n",
    "    GROUP BY complaint_type\n",
    "    ORDER BY COUNT(id) DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    dataframe = pd.read_sql_query(query, engine)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab53998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_2()\n",
    "plot_top_complaints_numbers(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6733574",
   "metadata": {},
   "source": [
    "### Visualization 3 - Correlation between Rent, Trees, and Complaints\n",
    "\n",
    "We are interested in understanding the relationships between rent prices, the number of trees, and the frequency of complaints in different zip codes from January 1st, 2015, to September 30th, 2023.\n",
    "\n",
    "- Chart 1: Rent vs. Trees:\n",
    "Explore how living costs relate to greenery. If bars go up, rent is higher; climbing markers indicate a greener neighborhood.\n",
    "\n",
    "- Chart 2: Rent vs. Complaints:\n",
    "Understand the link between rent and complaints. Higher bars denote higher rent, while markers reveal the neighborhood's activity level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ede37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rent_trees_complaints(df_merged):\n",
    "    \"\"\"\n",
    "    Plot a dual-axis bar chart showing the relationship between rent, number of trees, and number of complaints by zip code.\n",
    "\n",
    "    Parameters:\n",
    "    - df_merged (DataFrame): Input DataFrame containing merged information about rent, tree count, and complaint count.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays a dual-axis bar chart in the notebook.\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    zip_codes = df_merged[\"zipcode\"].astype(str).tolist()\n",
    "    rents = df_merged['average_rent']\n",
    "    tree_counts = df_merged['tree_count']\n",
    "    complaint_counts = df_merged['complaint_count']\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "    ax1.bar(zip_codes, rents, color='lightgreen', label='Rent')\n",
    "    ax1_twin = ax1.twinx()\n",
    "    ax1_twin.plot(zip_codes, tree_counts, color='darkgreen', marker='o', label='Trees')\n",
    "    ax1.set_ylabel('Rent ($)')\n",
    "    ax1_twin.set_ylabel('Number of Trees')\n",
    "    ax1.set_title('Rent and Number of Trees by Zip Code')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax1_twin.legend(loc='upper right')\n",
    "\n",
    "\n",
    "    ax2.bar(zip_codes, rents, color='skyblue', label='Rent')\n",
    "    ax2_twin = ax2.twinx()\n",
    "    ax2_twin.plot(zip_codes, complaint_counts, color='blue', marker='o', label='Complaints')\n",
    "    ax2.set_ylabel('Rent ($)')\n",
    "    ax2_twin.set_ylabel('Number of Complaints')\n",
    "    ax2.set_xlabel('Zip Code')\n",
    "    ax2.set_title('Rent and Number of Complaints by Zip Code')\n",
    "    ax2.legend(loc='upper left')\n",
    "    ax2_twin.legend(loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb8b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_3():\n",
    "    \"\"\"\n",
    "    Retrieve data for creating visualizations that show the relationship between rent, tree count, and complaint count by zip code.\n",
    "\n",
    "    Parameters:\n",
    "    - engine (sqlalchemy.engine.Engine): SQLAlchemy engine for connecting to the database.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Merged DataFrame containing information about rent, tree count, and complaint count by zip code.\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    query_rent_trees = \"\"\"\n",
    "    SELECT\n",
    "        zillow_datas.zipcode,\n",
    "        AVG(zillow_datas.rent) AS average_rent,\n",
    "        COUNT(trees.id) AS tree_count\n",
    "    FROM\n",
    "        zillow_datas\n",
    "    LEFT JOIN\n",
    "        trees ON zillow_datas.zipcode = trees.zipcode\n",
    "    WHERE\n",
    "        zillow_datas.date BETWEEN '2015-01-01' AND '2023-09-30'\n",
    "    GROUP BY\n",
    "        zillow_datas.zipcode;\n",
    "    \"\"\"\n",
    "\n",
    "    query_rent_complaints = \"\"\"\n",
    "    SELECT\n",
    "        zillow_datas.zipcode,\n",
    "        AVG(zillow_datas.rent) AS average_rent,\n",
    "        COUNT(nyc311s.id) AS complaint_count\n",
    "    FROM\n",
    "        zillow_datas\n",
    "    LEFT JOIN\n",
    "        nyc311s ON zillow_datas.zipcode = nyc311s.zipcode\n",
    "    WHERE\n",
    "        zillow_datas.date BETWEEN '2015-01-01' AND '2023-09-30'\n",
    "    GROUP BY\n",
    "        zillow_datas.zipcode;\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    df_rent_trees = pd.read_sql_query(query_rent_trees, engine)\n",
    "    \n",
    "    df_rent_complaints = pd.read_sql_query(query_rent_complaints, engine)\n",
    "\n",
    "    df = pd.merge(df_rent_trees, df_rent_complaints, on=['zipcode', 'average_rent'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_3()\n",
    "plot_rent_trees_complaints(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1566e",
   "metadata": {},
   "source": [
    "### Visualization 4 - Rent Affordability vs. Neighbourhood Issues\n",
    "\n",
    "We are curious that if it's possible to reduce the the noises and complaints if we can afford the high rent for the apartment. Our boxplot, classifying average rent into $1000 bins, provides insights into the correlation with 311 complaints across different zip codes. It seems true that as rent increases, the boxes become narrower, indicating potentially reduced noise and complaints in higher-rent apartments. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rent_complaints(df):\n",
    "    \"\"\"\n",
    "    Plot a boxplot showing the relationship between binned average rent and the number of 311 complaints by zip code.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Input DataFrame containing information about average rent, complaint count, and rent bins.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays a boxplot in the notebook.\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    df['rent_bin'] = pd.cut(df['avg_rent'], bins=range(0, int(df['avg_rent'].max()) + 1000, 1000), right=False)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.boxplot(x='rent_bin', y='complaint_count', data=df)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('Average Rent ($1000 bins)')\n",
    "    plt.ylabel('Number of 311 Complaints')\n",
    "    plt.title('311 Complaints vs. Average Rent by Zip Code')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_4():\n",
    "    \"\"\"\n",
    "    Retrieve data for creating visualizations that show the relationship between average rent and the number of 311 complaints by zip code.\n",
    "\n",
    "    Parameters:\n",
    "    - engine (sqlalchemy.engine.Engine): SQLAlchemy engine for connecting to the database.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: DataFrame containing information about average rent and complaint count by zip code.\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    query = '''\n",
    "    SELECT\n",
    "        zillow_datas.zipcode,\n",
    "        AVG(zillow_datas.rent) AS avg_rent,\n",
    "        COUNT(nyc311s.id) AS complaint_count\n",
    "    FROM\n",
    "        zillow_datas\n",
    "    JOIN\n",
    "        nyc311s ON zillow_datas.zipcode = nyc311s.zipcode\n",
    "    WHERE\n",
    "        zillow_datas.date BETWEEN '2023-09-01' AND '2023-09-30'\n",
    "        AND nyc311s.created_date BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "    GROUP BY\n",
    "        zillow_datas.zipcode\n",
    "        '''\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670a97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_4()\n",
    "plot_rent_complaints(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2459c",
   "metadata": {},
   "source": [
    "### Visualization 5 - Geospatial Snapshot: Recent 311 Incidents in Immediate Proximity\n",
    "\n",
    "We are trying to find that recent incidents in the immediate neighborhood. The geospatial plot shows a snapshot of 311 cases reported between January 1, 2023, and September 30, 2023, within a 1-kilometer radius of a central point. The blue markers represent incident locations, revealing the areas of recent concern. The red point marks the reference location for context. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89395649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_311_cases(df):\n",
    "    \"\"\"\n",
    "    Create a geospatial plot of the coordinates from the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): Input DataFrame containing geospatial information.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays a geospatial plot in the notebook.\n",
    "    ```\n",
    "    \"\"\"\n",
    "    # Decode the WKB geometry to shapely Points\n",
    "    df['geometry'] = df['geometry'].apply(lambda x: wkb.loads(x, hex=True))\n",
    "    \n",
    "    # Create a GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "    \n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    gdf.plot(ax = ax, color = 'blue', markersize=5)\n",
    "    ref_lat=40.80737875669467\n",
    "    ref_lon=-73.96253174434912 \n",
    "    plt.scatter(ref_lon, ref_lat, color='red', s=100, label='Reference Point', zorder=5)\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title('311 Cases from Jan 1, 2023 to Sep 30, 2023 within 1km radius')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query 311 cases\n",
    "def query_311_cases(latitude=40.80737875669467, longitude=-73.96253174434912, radius=1000):\n",
    "    \"\"\"\n",
    "    Query the database for 311 cases within a specified radius of the given latitude and longitude,\n",
    "    occurring between January 1st, 2023, and September 30th, 2023.\n",
    "\n",
    "    Parameters:\n",
    "    - latitude (float): Latitude of the center point (default is 40.80737875669467).\n",
    "    - longitude (float): Longitude of the center point (default is -73.96253174434912).\n",
    "    - radius (int): Radius in meters (default is 1000 meters).\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: DataFrame containing information about 311 cases.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # SQL query string\n",
    "    sql_query = f\"\"\"\n",
    "    SELECT created_date, complaint_type, zipcode, geometry\n",
    "    FROM nyc311s\n",
    "    WHERE created_date BETWEEN '2023-01-01' AND '2023-09-30'\n",
    "    AND ST_DWithin(\n",
    "        geometry::geography,\n",
    "        ST_SetSRID(ST_MakePoint({longitude}, {latitude})::geography, 4326),\n",
    "        {radius}\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Execute the query and return the results\n",
    "    df = pd.read_sql_query(sql_query, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc9487",
   "metadata": {},
   "outputs": [],
   "source": [
    " plot_311_cases(query_311_cases(latitude=40.80737875669467, longitude=-73.96253174434912, radius=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bb2aa",
   "metadata": {},
   "source": [
    "### Visualization 6 - Enhancing Greenery: Mapping Trees and New Tree Requests in NYC (Oct 2018 - Sep 2023)\n",
    "\n",
    "We are investigating that whether there are efforts that were made to enhance greenery in the New York City. This geospatial plot illustrates the locations of existing trees and areas with \"New Tree Request\" 311 complaints reported from October 1, 2018, to September 30, 2023. The green markers represent the current tree locations, while the red markers indicate places where residents have requested new trees. From the plot, we can observe that only some of the requests have been addressed, meaning that there remains room for improvement in addressing community needs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_geospatial_data(trees_df, complaints_df):\n",
    "    \"\"\"\n",
    "    Plot trees data and 'New Tree Request' complaints on a map.\n",
    "\n",
    "    Parameters:\n",
    "    trees_df (DataFrame): DataFrame containing trees data.\n",
    "    complaints_df (DataFrame): DataFrame containing 'New Tree Request' complaints data.\n",
    "    \"\"\"\n",
    "    # Convert WKB to shapely Points\n",
    "    trees_df['geometry'] = trees_df['geometry'].apply(wkb.loads, hex=True)\n",
    "    complaints_df['geometry'] = complaints_df['geometry'].apply(wkb.loads, hex=True)\n",
    "\n",
    "    # Create GeoDataFrames\n",
    "    trees_gdf = gpd.GeoDataFrame(trees_df, geometry='geometry')\n",
    "    complaints_gdf = gpd.GeoDataFrame(complaints_df, geometry='geometry')\n",
    "\n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    trees_gdf.plot(ax=ax, marker='o', color='green', markersize=5, label='Trees')\n",
    "    complaints_gdf.plot(ax=ax, marker='x', color='red', markersize=5, label='New Tree Requests')\n",
    "\n",
    "    # Set title and labels\n",
    "    ax.set_title('NYC Trees and New Tree Requests')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89336fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_geospatial_data():\n",
    "    \"\"\"\n",
    "    Query trees data and 'New Tree Request' complaints from the database.\n",
    "\n",
    "    Parameters:\n",
    "    conn: Database connection object.\n",
    "\n",
    "    Returns:\n",
    "    trees_df (DataFrame): DataFrame containing trees data.\n",
    "    complaints_df (DataFrame): DataFrame containing 'New Tree Request' complaints data.\n",
    "    \"\"\"\n",
    "    # SQL query for trees\n",
    "    trees_query = \"\"\"\n",
    "    SELECT id, created_at, geometry\n",
    "    FROM trees\n",
    "    \"\"\"\n",
    "\n",
    "    # SQL query for 'New Tree Request' complaints\n",
    "    complaints_query = \"\"\"\n",
    "    SELECT id, created_date, geometry\n",
    "    FROM nyc311s\n",
    "    WHERE complaint_type = 'New Tree Request'\n",
    "    AND created_date BETWEEN '2018-10-01' AND '2023-09-30'\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute queries and return dataframes\n",
    "    trees_df = pd.read_sql_query(trees_query, engine)\n",
    "    complaints_df = pd.read_sql_query(complaints_query, engine)\n",
    "\n",
    "    return trees_df, complaints_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_df, complaints_df=query_geospatial_data()\n",
    "plot_geospatial_data(trees_df, complaints_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
